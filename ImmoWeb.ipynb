{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6bda153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import lxml.html\n",
    "import time\n",
    "import random\n",
    "from random import randint\n",
    "import logging\n",
    "import collections\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "de86096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import typing\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "015f3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b761cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. make a dataset\\n    1. Initializing it with correct column names.\\n-\\n2. open webpage\\n3. extract the list as dict\\n-\\n4. write to dataset\\n5. keep doing this\\n6. write dataset to CSV\\n\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "1. make a dataset\n",
    "    1. Initializing it with correct column names.\n",
    "-\n",
    "2. open webpage\n",
    "3. extract the list as dict\n",
    "-\n",
    "4. write to dataset\n",
    "5. keep doing this\n",
    "6. write dataset to CSV\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a6732cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1298b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImmoWeb():\n",
    "    \n",
    "    def __init__(self, start_url=\"https://www.immoweb.be/fr/recherche/maison/a-vendre?countries=BE&page=1&orderBy=relevance\"):\n",
    "        self.start_url = start_url\n",
    "        self.advert_urls = []\n",
    "        self.advert_details = []\n",
    "        \n",
    "    def page_advert_urls(self, page_url, url_piece = \"annonce\"):\n",
    "        driver.get(page_url)\n",
    "        time.sleep(random.uniform(1.0, 2.0))\n",
    "        for elem in driver.find_elements_by_tag_name(\"a\"):\n",
    "            link = elem.get_attribute(\"href\")\n",
    "            if not link is None and url_piece in link:\n",
    "                self.advert_urls.append(link)\n",
    "\n",
    "    def readPagination(self):\n",
    "        \"\"\"\n",
    "        readPagination gathers all pages that contain independent ads. The first one is hardcoded and \n",
    "        aferwards it formats the URL as a string until no new ads are found.\n",
    "        \n",
    "        :return: a list of URLs that link to each page of a search query. \n",
    "        \"\"\"\n",
    "        # initialize a list for storing all the seperate links to individual ads.\n",
    "        #all_advert_urls = []\n",
    "        #advert_urls = []\n",
    "        counter = 2\n",
    "        print(self.start_url)\n",
    "        self.page_advert_urls(self.start_url)\n",
    "        \n",
    "        previous_adverts_amount = 0\n",
    "        adverts_amount = len(self.advert_urls)\n",
    "\n",
    "        while previous_adverts_amount < adverts_amount:\n",
    "            previous_adverts_amount = adverts_amount\n",
    "            \n",
    "            page_url = f\"https://www.immoweb.be/fr/recherche/maison/a-vendre?countries=BE&page={counter}&orderBy=relevance\"\n",
    "            self.page_advert_urls(page_url)\n",
    "            \n",
    "            adverts_amount = len(self.advert_urls)\n",
    "            counter += 1\n",
    "            \n",
    "    def readAdPage(self):\n",
    "        \"\"\"\n",
    "        Method the reads all the information on the page and writes it to a dict using the key, \n",
    "        value pairs used on the website in question. \n",
    "    \n",
    "        :inp_url: get the input URL that we will be gathering information from.\n",
    "        :return: a dict that stores scraped data\n",
    "        \"\"\"\n",
    "        for advert_url in self.advert_urls:\n",
    "            # initialize some variables.\n",
    "            detailsKeys = []\n",
    "            detailsValues = []\n",
    "            details = {}\n",
    "    \n",
    "            # grab the URL page code\n",
    "            driver.get(advert_url)\n",
    "    \n",
    "            # find the tables in the page and split data in 2 types, keys and values.\n",
    "            for desc_list in driver.find_elements_by_tag_name(\"th\"):\n",
    "                if desc_list.text != \"\":\n",
    "                    detailsKeys.append(desc_list.text)\n",
    "\n",
    "            for desc_list in driver.find_elements_by_tag_name(\"td\"):\n",
    "                if desc_list.text != \"\":\n",
    "                    if desc_list.find_elements_by_tag_name(\"a\") == []:\n",
    "                        if desc_list.find_elements_by_tag_name(\"span\") != []:\n",
    "                            detail = desc_list.text.split(\"\\n\")\n",
    "                            detailsValues.extend(detail[:-1])\n",
    "                        else:\n",
    "                            detailsValues.append(desc_list.text)\n",
    "\n",
    "            # build a dict containing all gathered data\n",
    "            for idx, x in enumerate(detailsKeys):\n",
    "                details[x] = detailsValues[idx]\n",
    "                \n",
    "            self.advert_details.append(details)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
