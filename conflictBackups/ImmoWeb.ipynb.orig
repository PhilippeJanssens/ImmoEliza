{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 11,
>>>>>>> 17146ca33a17f96da072bd33bb2d7822ef94169d
   "id": "f6bda153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from random import randint\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 12,
>>>>>>> 17146ca33a17f96da072bd33bb2d7822ef94169d
   "id": "de86096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "import typing\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 13,
>>>>>>> 17146ca33a17f96da072bd33bb2d7822ef94169d
   "id": "015f3951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "C:\\Users\\aubin\\AppData\\Local\\Temp/ipykernel_30432/2296700920.py:5: DeprecationWarning: use options instead of firefox_options\n",
=======
      "<ipython-input-13-30a6158f3f0a>:5: DeprecationWarning: use options instead of firefox_options\n",
>>>>>>> 17146ca33a17f96da072bd33bb2d7822ef94169d
      "  browser = webdriver.Firefox(firefox_options=opts)\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver import FirefoxOptions\n",
    "\n",
    "opts = FirefoxOptions()\n",
    "opts.add_argument(\"--headless\")\n",
    "browser = webdriver.Firefox(firefox_options=opts)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 14,
>>>>>>> 17146ca33a17f96da072bd33bb2d7822ef94169d
   "id": "3b761cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threading seems almost impossible..."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 15,
>>>>>>> 17146ca33a17f96da072bd33bb2d7822ef94169d
   "id": "a6732cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 16,
>>>>>>> 17146ca33a17f96da072bd33bb2d7822ef94169d
   "id": "1298b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImmoWeb():\n",
    "    \n",
    "    def __init__(self, driver, counter = 2, debug_mode = False, start_url=\"https://www.immoweb.be/fr/recherche/maison/a-vendre?countries=BE&page=1&orderBy=relevance\"):\n",
    "        self.driver = driver\n",
    "        self.start_url = start_url\n",
    "        self.advert_urls = []\n",
    "        self.advert_details = []\n",
    "        self.all_data = []\n",
    "        self.counter = counter\n",
    "        \n",
    "        self.debug = debug_mode\n",
    "        \n",
    "        \n",
    "    def scrape(self):\n",
    "        \"\"\"\n",
    "        Scrape methods calls other methods in the class in order. TODO add threading support.\n",
    "        \"\"\"\n",
    "        \n",
    "        # work in batches of 5\n",
    "        urls = self.readPagination(5)\n",
    "\n",
    "        for url in tqdm(self.advert_urls):\n",
    "            data = self.readAdPage(url)\n",
    "            self.all_data.append(data)\n",
    "\n",
    "        return [self.all_data, self.counter]\n",
    "            \n",
    "        \n",
    "    def page_advert_urls(self, page_url, url_piece = \"annonce\"):\n",
    "        \"\"\"\n",
    "        Method that gathers urls for each individual ad. \n",
    "        \n",
    "        :page_url: a url that links to a page containing several urls of individual ads\n",
    "        :return: a list containing all the urls to the front pages.\n",
    "        \"\"\"\n",
    "        # Init empty list to return gathered \n",
    "        url = []\n",
    "        \n",
    "        # call the driver get method with a time delay.\n",
    "        self.driver.get(page_url)\n",
    "        time.sleep(random.uniform(0.3, 0.8))\n",
    "        \n",
    "        # find all the links to individual ads.\n",
    "        for elem in self.driver.find_elements_by_tag_name(\"a\"):\n",
    "            link = elem.get_attribute(\"href\")\n",
    "            if not link is None and url_piece in link:\n",
    "                self.advert_urls.append(link)\n",
    "                url.append(link)\n",
    "                \n",
    "        return url\n",
    "       \n",
    "    def readPagination(self, batches):\n",
    "        \"\"\"\n",
    "        readPagination gathers all pages that contain independent ads. The first one is hardcoded and \n",
    "        aferwards it formats the URL as a string until no new ads are found.\n",
    "        \n",
    "        :return: a list of URLs that link to each page of a search query. \n",
    "        \"\"\"\n",
    "        # initialize a list for storing all the seperate links to individual ads.\n",
    "        batch = 0\n",
    "        max_batch = batches\n",
    "        \n",
    "        urls = ['init']\n",
    "        \n",
    "        # loop until no results are found\n",
    "        while batch < max_batch:\n",
    "            \n",
    "            page_url = f\"https://www.immoweb.be/fr/recherche/maison/a-vendre?countries=BE&page={self.counter}&orderBy=postal_code\"\n",
    "            urls = self.page_advert_urls(page_url)\n",
    "            \n",
    "            adverts_amount = len(urls)\n",
    "            self.counter += 1\n",
    "            batch += 1\n",
    "            \n",
    "        return urls\n",
    "        \n",
    "            \n",
    "    def readAdPage(self, inp_url):\n",
    "        \"\"\"\n",
    "        Method that reads all the information on the page and writes it to a dict using the key, \n",
    "        value pairs used on the website in question. \n",
    "    \n",
    "        :inp_url: get the input URL that we will be gathering information from.\n",
    "        :return: a dict that stores scraped data\n",
    "        \"\"\"\n",
    "\n",
    "        # initialize some variables.\n",
    "        detailsKeys = []\n",
    "        detailsValues = []\n",
    "        details = {}\n",
    "\n",
    "        # grab the URL page code\n",
    "        self.driver.get(inp_url)\n",
    "\n",
    "        # find the tables in the page and split data in 2 types, keys and values.\n",
    "        for desc_list in self.driver.find_elements_by_tag_name(\"th\"):\n",
    "            if desc_list.text != \"\":\n",
    "                detailsKeys.append(desc_list.text)\n",
    "\n",
    "        for desc_list in self.driver.find_elements_by_tag_name(\"td\"):\n",
    "            if desc_list.text != \"\":\n",
    "                if desc_list.find_elements_by_tag_name(\"a\") == []:\n",
    "                    if desc_list.find_elements_by_tag_name(\"span\") != []:\n",
    "                        detail = desc_list.text.split(\"\\n\")\n",
    "                        detailsValues.extend(detail[:-1])\n",
    "                    else:\n",
    "                        detailsValues.append(desc_list.text)\n",
    "\n",
    "        # build a dict containing all gathered data\n",
    "        try:\n",
    "            for idx, x in enumerate(detailsKeys):\n",
    "                details[x] = detailsValues[idx]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        self.advert_details.append(details)\n",
    "\n",
    "        return details\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 17,
>>>>>>> 17146ca33a17f96da072bd33bb2d7822ef94169d
   "id": "78a610d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_read = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34775366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "6891d223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e76284",
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "execution_count": 18,
   "id": "6891d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = ImmoWeb(debug_mode = True, counter = data_read + 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34e76284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'tqdm' has no attribute 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8dca3f13412f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-d193fcb956e5>\u001b[0m in \u001b[0;36mscrape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0murls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadPagination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvert_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadAdPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'tqdm' has no attribute 'tqdm'"
     ]
    }
   ],
   "source": [
    "data, data_read = scraper.scrape()"
   ]
>>>>>>> 17146ca33a17f96da072bd33bb2d7822ef94169d
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0a6504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a67e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2343a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8db768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b85a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e789e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27121484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32268df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a6d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threadedScraper(driver, first_index):\n",
    "    scraper = ImmoWeb(driver = driver, debug_mode = True, counter = first_index)\n",
    "    data, data_read = scraper.scrape()\n",
    "    dataframe = pd.DataFrame(data)\n",
    "    filename = f\"immoweb/immoweb_batch_{first_index+1}_{data_read}.csv\"\n",
    "    dataframe.to_csv(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da12178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "540401c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_read = 275\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54a71993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [08:17<00:00,  3.21s/it]\n",
      "100%|██████████| 150/150 [07:45<00:00,  3.10s/it]\n",
      "100%|██████████| 152/152 [07:34<00:00,  2.99s/it]\n",
      "100%|██████████| 151/151 [06:08<00:00,  2.44s/it]\n",
      "100%|██████████| 153/153 [07:21<00:00,  2.89s/it]\n",
      "100%|██████████| 150/150 [05:46<00:00,  2.31s/it]\n",
      "100%|██████████| 151/151 [05:54<00:00,  2.35s/it]\n",
      "100%|██████████| 153/153 [04:57<00:00,  1.95s/it]\n",
      "100%|██████████| 150/150 [05:29<00:00,  2.19s/it]\n",
      "100%|██████████| 152/152 [06:00<00:00,  2.37s/it]\n",
      "100%|██████████| 150/150 [06:26<00:00,  2.58s/it]\n"
     ]
    }
   ],
   "source": [
    "while data_read < 330:\n",
    "    driver1 = webdriver.Firefox()\n",
    "    try: \n",
    "        threadedScraper(driver1, data_read)\n",
    "    except:\n",
    "        print(f\"FAILURE AT PAGE {data_read}\")\n",
    "    \n",
    "    driver1.quit()\n",
    "    data_read += 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1a182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [05:51<00:00,  2.34s/it]\n",
      "100%|██████████| 154/154 [09:06<00:00,  3.55s/it]\n",
      "100%|██████████| 154/154 [06:48<00:00,  2.65s/it]\n",
      "100%|██████████| 153/153 [06:58<00:00,  2.73s/it]\n",
      "100%|██████████| 151/151 [05:03<00:00,  2.01s/it]\n",
      "100%|██████████| 151/151 [06:04<00:00,  2.41s/it]\n",
      "100%|██████████| 155/155 [07:03<00:00,  2.73s/it]\n",
      "100%|██████████| 153/153 [09:56<00:00,  3.90s/it]\n",
      "100%|██████████| 154/154 [08:27<00:00,  3.30s/it]\n",
      "100%|██████████| 155/155 [08:03<00:00,  3.12s/it]\n",
      "100%|██████████| 153/153 [08:05<00:00,  3.17s/it]\n",
      "100%|██████████| 151/151 [07:40<00:00,  3.05s/it]\n",
      "100%|██████████| 153/153 [09:13<00:00,  3.62s/it]\n"
     ]
    }
   ],
   "source": [
    "data_read = 0\n",
    "\n",
    "while data_read < 200:\n",
    "    driver1 = webdriver.Firefox()\n",
    "    try: \n",
    "        threadedScraper(driver1, data_read)\n",
    "    except:\n",
    "        print(f\"FAILURE AT PAGE {data_read}\")\n",
    "    \n",
    "    driver1.quit()\n",
    "    data_read += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc92de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30904da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e129cdce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0532a457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36014490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e6ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2fb33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e854f616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7688857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3342fe17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee64e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8071bb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68ddf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ccc28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
