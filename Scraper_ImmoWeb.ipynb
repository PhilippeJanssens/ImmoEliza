{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6bda153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from random import randint\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de86096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "import typing\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015f3951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aubin\\AppData\\Local\\Temp/ipykernel_26648/2296700920.py:5: DeprecationWarning: use options instead of firefox_options\n",
      "  browser = webdriver.Firefox(firefox_options=opts)\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver import FirefoxOptions\n",
    "\n",
    "opts = FirefoxOptions()\n",
    "opts.add_argument(\"--headless\")\n",
    "browser = webdriver.Firefox(firefox_options=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b761cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threading seems almost impossible..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6732cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1298b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImmoWeb():\n",
    "    \"\"\"\n",
    "    This class and it's scrape method can be used to gather all data from the website\n",
    "    www.immoweb.be.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, driver, counter = 2, debug_mode = False, start_url=\"https://www.immoweb.be/fr/recherche/maison/a-vendre?countries=BE&page=1&orderBy=relevance\"):\n",
    "        \"\"\"\n",
    "        :driver: inputs which driver will be used for scraping.\n",
    "        :debug_mode: Flag to trigger some print statements, useful for debugging.\n",
    "        :start_url: Url of the first search front page (sorted by postal code for continuity) .\n",
    "        \"\"\"\n",
    "        self.driver = driver\n",
    "        self.start_url = start_url\n",
    "        self.advert_urls = []\n",
    "        self.advert_details = []\n",
    "        self.all_data = []\n",
    "        self.debug = debug_mode\n",
    "        \n",
    "        # counter, used for selecting which batch to start from.\n",
    "        self.counter = counter      \n",
    "        \n",
    "    def scrape(self):\n",
    "        \"\"\"\n",
    "        Scrape methods calls other methods in the class in order.\n",
    "        \"\"\"\n",
    "        \n",
    "        # work in batches of 5\n",
    "        urls = self.readPagination(5)\n",
    "\n",
    "        for url in tqdm(self.advert_urls):\n",
    "            data = self.readAdPage(url)\n",
    "            self.all_data.append(data)\n",
    "\n",
    "        return [self.all_data, self.counter]\n",
    "            \n",
    "        \n",
    "    def page_advert_urls(self, page_url, url_piece = \"annonce\"):\n",
    "        \"\"\"\n",
    "        Method that gathers urls for each individual ad. \n",
    "        \n",
    "        :page_url: a url that links to a page containing several urls of individual ads\n",
    "        :return: a list containing all the urls to the front pages.\n",
    "        \"\"\"\n",
    "        # Init empty list to return gathered \n",
    "        url = []\n",
    "        \n",
    "        # call the driver get method with a time delay.\n",
    "        self.driver.get(page_url)\n",
    "        time.sleep(random.uniform(0.3, 0.8))\n",
    "        \n",
    "        # find all the links to individual ads.\n",
    "        for elem in self.driver.find_elements_by_tag_name(\"a\"):\n",
    "            link = elem.get_attribute(\"href\")\n",
    "            if not link is None and url_piece in link:\n",
    "                self.advert_urls.append(link)\n",
    "                url.append(link)\n",
    "                \n",
    "        return url\n",
    "       \n",
    "    def readPagination(self, batches):\n",
    "        \"\"\"\n",
    "        readPagination gathers all pages that contain independent ads. The first one is hardcoded and \n",
    "        aferwards it formats the URL as a string until no new ads are found.\n",
    "        \n",
    "        :return: a list of URLs that link to each page of a search query. \n",
    "        \"\"\"\n",
    "        # initialize a list for storing all the seperate links to individual ads.\n",
    "        batch = 0\n",
    "        max_batch = batches\n",
    "        \n",
    "        urls = ['init']\n",
    "        \n",
    "        # loop until no results are found\n",
    "        while batch < max_batch:\n",
    "            \n",
    "            page_url = f\"https://www.immoweb.be/fr/recherche/maison/a-vendre?countries=BE&page={self.counter}&orderBy=postal_code\"\n",
    "            urls = self.page_advert_urls(page_url)\n",
    "            \n",
    "            adverts_amount = len(urls)\n",
    "            self.counter += 1\n",
    "            batch += 1\n",
    "            \n",
    "        return urls\n",
    "        \n",
    "            \n",
    "    def readAdPage(self, inp_url):\n",
    "        \"\"\"\n",
    "        Method that reads all the information on the page and writes it to a dict using the key, \n",
    "        value pairs used on the website in question. \n",
    "    \n",
    "        :inp_url: get the input URL that we will be gathering information from.\n",
    "        :return: a dict that stores scraped data\n",
    "        \"\"\"\n",
    "\n",
    "        # initialize some variables.\n",
    "        detailsKeys = []\n",
    "        detailsValues = []\n",
    "        details = {}\n",
    "\n",
    "        # grab the URL page code\n",
    "        self.driver.get(inp_url)\n",
    "\n",
    "        # find the tables in the page and split data in 2 types, keys and values.\n",
    "        for desc_list in self.driver.find_elements_by_tag_name(\"th\"):\n",
    "            if desc_list.text != \"\":\n",
    "                detailsKeys.append(desc_list.text)\n",
    "\n",
    "        for desc_list in self.driver.find_elements_by_tag_name(\"td\"):\n",
    "            if desc_list.text != \"\":\n",
    "                if desc_list.find_elements_by_tag_name(\"a\") == []:\n",
    "                    if desc_list.find_elements_by_tag_name(\"span\") != []:\n",
    "                        detail = desc_list.text.split(\"\\n\")\n",
    "                        detailsValues.extend(detail[:-1])\n",
    "                    else:\n",
    "                        detailsValues.append(desc_list.text)\n",
    "\n",
    "        # build a dict containing all gathered data\n",
    "        try:\n",
    "            for idx, x in enumerate(detailsKeys):\n",
    "                details[x] = detailsValues[idx]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        self.advert_details.append(details)\n",
    "\n",
    "        return details\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55479c5",
   "metadata": {},
   "source": [
    "def threadedScraper(driver, first_index):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    scraper = ImmoWeb(driver = driver, debug_mode = True, counter = first_index)\n",
    "    data, data_read = scraper.scrape()\n",
    "    dataframe = pd.DataFrame(data)\n",
    "    filename = f\"immoweb/immoweb_batch_{first_index+1}_{data_read}.csv\"\n",
    "    dataframe.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34775366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use following two cells to run the scraper in batches, define the range of batches\n",
    "# you want to gather in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6891d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_read = 180 #SET STARTING BATCH HERE\n",
    "max_batch = 200 #SET ENDING BATCH HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34e76284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [09:46<00:00,  3.84s/it]\n",
      "100%|██████████| 154/154 [08:31<00:00,  3.32s/it]\n",
      " 99%|█████████▊| 153/155 [11:36<00:09,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILURE AT PAGE 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 148/153 [08:07<00:16,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILURE AT PAGE 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "while data_read < max_batch:\n",
    "    driver1 = webdriver.Firefox()\n",
    "    try: \n",
    "        threadedScraper(driver1, data_read)\n",
    "    except:\n",
    "        print(f\"FAILURE AT PAGE {data_read}\")\n",
    "    \n",
    "    driver1.quit()\n",
    "    data_read += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0a6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the following cell to run in threads. Be careful, because memory usage is very high and can\n",
    "# and will cause crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e0f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = 0 #SET THE FIRST INDEX OF BATCH YOU WANT TO RUN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a67e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver1 = webdriver.Firefoc()\n",
    "thread1 = Thread(target=threadedScraper, args=(driver1, first_batch))\n",
    "thread1.start()\n",
    "\n",
    "driver2 = webdriver.Firefoc()\n",
    "thread2 = Thread(target=threadedScraper, args=(driver2, first_batch))\n",
    "thread2.start()\n",
    "\n",
    "driver3 = webdriver.Firefoc()\n",
    "thread3 = Thread(target=threadedScraper, args=(driver3, first_batch))\n",
    "thread3.start()\n",
    "\n",
    "driver4 = webdriver.Firefoc()\n",
    "thread4 = Thread(target=threadedScraper, args=(driver4, first_batch))\n",
    "thread4.start()\n",
    "\n",
    "driver5 = webdriver.Firefoc()\n",
    "thread5 = Thread(target=threadedScraper, args=(driver5, first_batch))\n",
    "thread5.start()\n",
    "\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "thread4.join()\n",
    "thread5.join()\n",
    "\n",
    "driver1.quit()\n",
    "driver2.quit()\n",
    "driver3.quit()\n",
    "driver4.quit()\n",
    "driver5.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2343a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8db768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b85a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e789e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27121484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32268df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a6d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da12178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540401c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a71993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1a182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc92de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30904da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e129cdce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0532a457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36014490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcff24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdafbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82437a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0449d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2703a3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fac0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c202b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100f321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0385542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
