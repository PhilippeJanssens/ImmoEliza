{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1939f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import typing\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f06c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElissaScraper():\n",
    "    \"\"\"\n",
    "    This class and it's scrape method can be used to gather all data from the website\n",
    "    www.immoelisa.be.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.first_page = 'https://immoelissa.be/immobilier/?sort=prix-c'\n",
    "        self.data = []\n",
    "        self.driver = webdriver.Firefox()\n",
    "    \n",
    "    def scrape(self):\n",
    "        \"\"\"\n",
    "        Scrape methods calls other methods in the class in order. \n",
    "        readPagination method gives all the individual ad urls, and\n",
    "        for each of these we run the readAdPage method\n",
    "        \"\"\"\n",
    "        \n",
    "        all_advert_urls = readPagination()\n",
    "        \n",
    "        for url in all_advert_urls:\n",
    "            result = readAdPage(url)\n",
    "            self.data.append(result)\n",
    "    \n",
    "    def properties_url(self, inp_url):\n",
    "        \"\"\"\n",
    "        method that gathers all the individual links from each front page.\n",
    "        \n",
    "        :inp_url: link to the front page\n",
    "        :return: a list of all the urls on the page\n",
    "        \"\"\"\n",
    "        # initialize empty list to return the data\n",
    "        url = []\n",
    "        \n",
    "        # get page data with selenium driver\n",
    "        self.driver.get(inp_url)\n",
    "        time.sleep(random.uniform(1.0, 2.0))\n",
    "        \n",
    "        # gather data from the html code.\n",
    "        for elem in driver.find_elements_by_tag_name(\\\"a\\\"):\n",
    "            link = elem.get_attribute(\\\"href\\\")\n",
    "            if not link is None and \\\"annonces\\\" in link:\n",
    "                url.append(link)\n",
    "                                      \n",
    "        return url\n",
    "    \n",
    "    def readPagination(self):\n",
    "        \"\"\"\n",
    "        readPagination switches between the front pages that contain \n",
    "        independent ads. The first one is hardcoded and aferwards it \n",
    "        formats the URL as a string until no new ads are found.\n",
    "\n",
    "        :return: a list of URLs that link to each page of a search query. \n",
    "        \"\"\"\n",
    "\n",
    "        # initiaze a list for storing all the page URLS\n",
    "        page_urls = []\n",
    "        page_urls.append(self.first_page)\n",
    "\n",
    "        # initialize a list for storing all the seperate links to individual ads.\n",
    "        all_advert_urls = []\n",
    "        advert_urls = []\n",
    "        counter = 2\n",
    "\n",
    "        advert_urls = properties_url(self.first_page)\n",
    "        all_advert_urls.extend(advert_urls)\n",
    "\n",
    "        while advert_urls != []:\n",
    "            url2 = f\\\"https://immoelissa.be/immobilier/?pg={counter}&sort=prix-c\\\"\n",
    "            advert_urls = properties_url(url2)\n",
    "            all_advert_urls.extend(advert_urls)\n",
    "            counter += 1\n",
    "            print(advert_urls)\n",
    "        \n",
    "        return all_advert_urls\n",
    "    \n",
    "    def readAdPage(self, inp_url):\n",
    "        \"\"\"\n",
    "        Method the reads all the information on the page and writes it to a dict using the key, \n",
    "        value pairs used on the website in question. \n",
    "\n",
    "        :inp_url: get the input URL that we will be gathering information from.\n",
    "        :return: a dict that stores scraped data\n",
    "        \"\"\"\n",
    "\n",
    "        # initialize some variables.\n",
    "        detailsKeys = []\n",
    "        detailsValues = []\n",
    "        details = {}\n",
    "\n",
    "        # grab the URL page code\n",
    "        driver.get(inp_url)\n",
    "\n",
    "        # find the tables in the page and split data in 2 types, keys and values.\n",
    "        for desc_list in driver.find_elements_by_tag_name(\\\"dt\\\"):\n",
    "            detail = desc_list.text.split(\\\"\\\\n\\\")\n",
    "            detailsKeys.extend(detail)\n",
    "\n",
    "        for desc_list in driver.find_elements_by_tag_name(\\\"dd\\\"):\n",
    "            detail = desc_list.text.split(\\\"\\\\n\\\")\n",
    "            detailsValues.extend(detail)\n",
    "\n",
    "        # build a dict containing all gathered data\n",
    "        for idx, x in enumerate(detailsKeys):\n",
    "            details[x] = detailsValues[idx]\n",
    "\n",
    "        return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd041ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049c61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following cell runs the scraper for the full website. \n",
    "# Use of batches and threading have not been used because the \n",
    "# dataset is small.\n",
    "scraper = ElissaScraper()\n",
    "scraper.scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205cc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a75e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc5b061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34ca14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adabe838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896fb151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f72375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d9ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db2cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a843166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3afca49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac63632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
